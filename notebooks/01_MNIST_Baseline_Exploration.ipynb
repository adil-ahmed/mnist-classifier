{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfa4b6b6-198d-4eae-8438-69bc46c4c6e0",
   "metadata": {},
   "source": [
    "# üß† MNIST Digit Classifier with PyTorch\n",
    "\n",
    "This notebook trains a simple neural network to classify handwritten digits (0‚Äì9) from the MNIST dataset using PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b331396-5662-455b-9cac-ca42b96ab371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf3468-f4b8-44f5-8617-049221df1836",
   "metadata": {},
   "source": [
    "## üì¶ Setup & Hyperparameters\n",
    "\n",
    "We define:\n",
    "- `input_size = 28x28 = 784` (since MNIST images are 28√ó28 pixels)\n",
    "- `hidden_size = 64` (number of neurons in the hidden layer)\n",
    "- `num_classes = 10` (digits from 0 to 9)\n",
    "- `batch_size`, `learning_rate`, and `epochs` for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cb8a02e-29fd-4223-a7c3-7726f88ec1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "hidden_size = 64\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d10c4f2-d5a0-4efa-ad7c-69d44a7ad692",
   "metadata": {},
   "source": [
    "## üßπ Load and Transform the MNIST Dataset\n",
    "\n",
    "We use `torchvision.datasets.MNIST` to load training and test sets. Images are converted to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7707889-033f-44f7-9f63-a88c8b91d78b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6545047d-0fe2-4faf-87fa-5819cf117c35",
   "metadata": {},
   "source": [
    "## üß± PyTorch Data Pipeline: Dataset vs DataLoader\n",
    "\n",
    "Whenever we work with a dataset (e.g. MNIST, CIFAR10, etc.), we typically follow this **standard PyTorch pattern**:\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Step 1: Load Dataset\n",
    "\n",
    "```python\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Training dataset\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "# Test dataset\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776749c-a6f7-486e-b404-128e65b6dc5b",
   "metadata": {},
   "source": [
    "\n",
    "### ‚úÖ Step 2: Create DataLoaders\n",
    "\n",
    "```python\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1100245f-8e14-479d-b4d4-815d1a16b97f",
   "metadata": {},
   "source": [
    "***We almost always go:***\n",
    "```python\n",
    "Dataset ‚ûú DataLoader ‚ûú Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1428460-83e2-497d-b5bf-d11ae12218c6",
   "metadata": {},
   "source": [
    "## üß± Neural Network Architecture\n",
    "\n",
    "A simple feedforward neural network with:\n",
    "- One hidden layer with ReLU activation\n",
    "- Output layer with 10 neurons (for digits 0‚Äì9)\n",
    "- CrossEntropyLoss, which includes Softmax internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab59bbb-3ebb-492a-9fd1-3d3e3ef578ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3a974c-a3fd-4dbd-8a4c-6df5eca6e5ed",
   "metadata": {},
   "source": [
    "### üìå Understanding the Code: `NeuralNet` Class\n",
    "\n",
    "- **`class NeuralNet(nn.Module)`**  \n",
    "  Defines a neural network class by inheriting from `torch.nn.Module`.\n",
    "\n",
    "- **`__init__()` constructor**\n",
    "  - `linear1`: Fully connected layer from input ‚Üí hidden layer.\n",
    "  - `ReLU`: Non-linear activation function that adds non-linearity to the model.\n",
    "  - `linear2`: Fully connected layer from hidden layer ‚Üí output layer (final class scores).\n",
    "\n",
    "- **`forward()` method**  \n",
    "  This defines how data flows through the network:\n",
    "  - Input is passed to `linear1`\n",
    "  - Output goes through the ReLU activation\n",
    "  - Result is passed to `linear2` to produce the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a36375-93b8-4ff7-99cf-8ab61b3d9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e195b5-4e9d-4596-a98b-9108677714d2",
   "metadata": {},
   "source": [
    "**`model = NeuralNet(...)`**  \n",
    "  Instantiates the model with the given architecture:\n",
    "  - `input_size`: Size of the input features (e.g., 784 for 28x28 MNIST images)\n",
    "  - `hidden_size`: Number of hidden neurons (e.g., 64)\n",
    "  - `num_classes`: Total number of output classes (e.g., 10 for digits 0‚Äì9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225f16f-a947-4bc0-bcc1-1c8006226f24",
   "metadata": {},
   "source": [
    "## üéØ Loss Function & Optimizer\n",
    "\n",
    "We use:\n",
    "- `CrossEntropyLoss` (combines `LogSoftmax` and `NLLLoss`)\n",
    "- `Adam` optimizer for faster convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e1d75b8-6674-4323-b213-3cc01c7f3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fc18d-9cb2-4d93-a2f8-d6d1e5e1d0d9",
   "metadata": {},
   "source": [
    "## üèãÔ∏è Training the Model\n",
    "\n",
    "We loop through the data multiple times (epochs), performing:\n",
    "- Forward pass\n",
    "- Loss computation\n",
    "- Backward pass\n",
    "- Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc68de2a-b3f2-4ee7-92ac-b944ae0d69fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/938], Loss: 0.4399\n",
      "Epoch [1/5], Step [200/938], Loss: 0.4252\n",
      "Epoch [1/5], Step [300/938], Loss: 0.3026\n",
      "Epoch [1/5], Step [400/938], Loss: 0.3713\n",
      "Epoch [1/5], Step [500/938], Loss: 0.1903\n",
      "Epoch [1/5], Step [600/938], Loss: 0.3173\n",
      "Epoch [1/5], Step [700/938], Loss: 0.1238\n",
      "Epoch [1/5], Step [800/938], Loss: 0.1656\n",
      "Epoch [1/5], Step [900/938], Loss: 0.2141\n",
      "Epoch [2/5], Step [100/938], Loss: 0.1938\n",
      "Epoch [2/5], Step [200/938], Loss: 0.0804\n",
      "Epoch [2/5], Step [300/938], Loss: 0.0514\n",
      "Epoch [2/5], Step [400/938], Loss: 0.3999\n",
      "Epoch [2/5], Step [500/938], Loss: 0.1085\n",
      "Epoch [2/5], Step [600/938], Loss: 0.1009\n",
      "Epoch [2/5], Step [700/938], Loss: 0.1515\n",
      "Epoch [2/5], Step [800/938], Loss: 0.2240\n",
      "Epoch [2/5], Step [900/938], Loss: 0.2875\n",
      "Epoch [3/5], Step [100/938], Loss: 0.1774\n",
      "Epoch [3/5], Step [200/938], Loss: 0.0853\n",
      "Epoch [3/5], Step [300/938], Loss: 0.0574\n",
      "Epoch [3/5], Step [400/938], Loss: 0.1598\n",
      "Epoch [3/5], Step [500/938], Loss: 0.1482\n",
      "Epoch [3/5], Step [600/938], Loss: 0.1012\n",
      "Epoch [3/5], Step [700/938], Loss: 0.1531\n",
      "Epoch [3/5], Step [800/938], Loss: 0.0957\n",
      "Epoch [3/5], Step [900/938], Loss: 0.1317\n",
      "Epoch [4/5], Step [100/938], Loss: 0.1411\n",
      "Epoch [4/5], Step [200/938], Loss: 0.1747\n",
      "Epoch [4/5], Step [300/938], Loss: 0.1105\n",
      "Epoch [4/5], Step [400/938], Loss: 0.1204\n",
      "Epoch [4/5], Step [500/938], Loss: 0.1797\n",
      "Epoch [4/5], Step [600/938], Loss: 0.4165\n",
      "Epoch [4/5], Step [700/938], Loss: 0.0881\n",
      "Epoch [4/5], Step [800/938], Loss: 0.1401\n",
      "Epoch [4/5], Step [900/938], Loss: 0.0437\n",
      "Epoch [5/5], Step [100/938], Loss: 0.0660\n",
      "Epoch [5/5], Step [200/938], Loss: 0.1016\n",
      "Epoch [5/5], Step [300/938], Loss: 0.1171\n",
      "Epoch [5/5], Step [400/938], Loss: 0.0649\n",
      "Epoch [5/5], Step [500/938], Loss: 0.0361\n",
      "Epoch [5/5], Step [600/938], Loss: 0.2089\n",
      "Epoch [5/5], Step [700/938], Loss: 0.1257\n",
      "Epoch [5/5], Step [800/938], Loss: 0.0900\n",
      "Epoch [5/5], Step [900/938], Loss: 0.0738\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.view(-1, 28*28)  # Flatten\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcdb47e-ab1e-4257-9842-89a2192a0d0f",
   "metadata": {},
   "source": [
    "### Training Loop Explanation\n",
    "\n",
    "- **Outer loop (`for epoch in range(num_epochs)`):** Runs the training process multiple times over the whole dataset.\n",
    "- **Inner loop (`for i, (images, labels) in enumerate(train_loader)`):** Goes through the dataset batch by batch.\n",
    "- **Flatten images (`images.view(-1, 28*28)`):** Converts each 28x28 image into a 1D vector of size 784 so the model can process it.\n",
    "- **Forward pass (`outputs = model(images)`):** Sends input images into the model to get predictions.\n",
    "- **Loss calculation (`loss = criterion(outputs, labels)`):** Measures how far predictions are from the true labels.\n",
    "- **Zero gradients (`optimizer.zero_grad()`):** Clears old gradients from the last step.\n",
    "- **Backward pass (`loss.backward()`):** Computes gradients (how to adjust weights).\n",
    "- **Update weights (`optimizer.step()`):** Updates model parameters using gradients and optimizer.\n",
    "- **Progress print:** Every 100 steps, prints current epoch, step, and loss to track training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d41c28d-0d43-4262-a0d0-6a7f5384ef6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.75%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # switch to evaluation mode\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589e30ed-ba12-4bcb-a509-fbd840fcd07e",
   "metadata": {},
   "source": [
    "### Evaluation Loop Explanation\n",
    "\n",
    "- **`model.eval()`**  \n",
    "  Switches the model into **evaluation mode**. This turns off certain training behaviors (like dropout and batch normalization updates), making the model more stable during testing.\n",
    "\n",
    "- **`with torch.no_grad():`**  \n",
    "  Disables gradient tracking since we don‚Äôt need to update weights during evaluation. This saves memory and speeds up computation.\n",
    "\n",
    "- **Initialize counters (`correct = 0, total = 0`)**  \n",
    "  We prepare to keep track of how many predictions are correct vs. the total number of test samples.\n",
    "\n",
    "- **Loop over batches (`for images, labels in test_loader`)**  \n",
    "  Goes through the test dataset in batches.\n",
    "\n",
    "- **Flatten images (`images.view(-1, 28*28)`)**  \n",
    "  Converts each test image from 28√ó28 pixels into a vector of size 784, just like we did in training.\n",
    "\n",
    "- **Forward pass (`outputs = model(images)`)**  \n",
    "  Sends the test images through the trained model to get predicted probabilities (logits).\n",
    "\n",
    "- **Get predictions (`_, predicted = torch.max(outputs.data, 1)`)**  \n",
    "  Chooses the class with the highest score (the model‚Äôs prediction) for each image.\n",
    "\n",
    "- **Count total samples and correct predictions**  \n",
    "  - `total += labels.size(0)` adds the number of samples in the batch.  \n",
    "  - `correct += (predicted == labels).sum().item()` counts how many predictions match the true labels.\n",
    "\n",
    "- **Final accuracy calculation**  \n",
    "  After looping through all test data, we compute accuracy as:  \n",
    "  Accuracy = $\\frac{\\text{correct predictions}}{\\text{total samples}} \\times 100$\n",
    "  and print it as a percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae9a12b-365c-4202-9a1a-1c10ec59d405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
